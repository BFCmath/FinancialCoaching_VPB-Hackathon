# Plan: Evolving from Prompt Tester to Multi-Agent Orchestrator

This document outlines the plan to upgrade the `orchestrator_test` project from a single-output prompt testing lab to a true multi-agent orchestrator capable of calling multiple worker agents in parallel.

---

### **Phase 1: Enable Parallel Tool-Calling (The Quick Way)**

This phase focuses on adapting the current structure to allow the Language Model (LLM) to call multiple tools in a single turn without adding new dependencies.

#### **Step 1: Update the Core Prompt (`prompt.py`)**

**Goal:** Instruct the model to call multiple tools directly instead of using a single meta-tool like `route_to_multiple_workers`.

*   **Action:** In `ROUTING_PROMPT`, remove the rule: `ALWAYS call exactly ONE tool per response`.
*   **Action:** Update the main instruction to explicitly encourage calling all necessary tools for a given request.
*   **Action:** Rewrite the `COMPLEX REQUEST EXAMPLES` to show direct multi-tool calls.

    *   **Before:**
        ```
        User: "I spent $100 on groceries and want to add a vacation jar with 15%"
        → route_to_multiple_workers(tasks=[...])
        ```
    *   **After (The New Goal):**
        ```
        User: "I spent $100 on groceries and want to add a vacation jar with 15%"
        → call tool route_to_transaction_classifier(task_description="log $100 grocery transaction")
        → call tool route_to_jar_manager(task_description="add vacation jar with 15% allocation")
        ```

#### **Step 2: Simplify the Available Tools (`tools.py`)**

**Goal:** Remove the now-obsolete meta-tools used for simulating multi-agent logic.

*   **Action:** Delete the `route_to_multiple_workers` and `decompose_complex_request` functions from the file.
*   **Action:** Update the `ALL_TOOLS` list to only contain the five direct worker-routing tools (e.g., `route_to_jar_manager`, `route_to_transaction_classifier`, etc.).

#### **Step 3: Upgrade the Orchestrator Logic (`main.py`)**

**Goal:** Adapt the core logic to handle a list of tool calls instead of a single one.

*   **Action:** In the `analyze_request` function, modify the code to iterate through the entire `response.tool_calls` list returned by the LLM.
*   **Action:** Change the function's return type to output a list of all tool calls generated by the model, rather than a single dictionary.

#### **Step 4: Enhance the Display Logic (`main.py` and `test.py`)**

**Goal:** Update the user interface to clearly display the list of parallel tool calls.

*   **Action:** Refactor the `display_result` function in `main.py` to iterate through the list of tool calls and print each one cleanly.
*   **Action:** Ensure the `test.py` interactive loop correctly passes the list to the new display function.
